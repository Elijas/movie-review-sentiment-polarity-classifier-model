=== Test set accuracy ===
78.0%
    
=== Performance evaluation ===
              precision    recall  f1-score   support

           0      0.796     0.755     0.775      1070
           1      0.766     0.805     0.785      1063

    accuracy                          0.780      2133
   macro avg      0.781     0.780     0.780      2133
weighted avg      0.781     0.780     0.780      2133


=== Confusion matrix ===
True Positives: 856
True Negatives: 808
False Positives: 262
False Negatives: 207

=== Training result ===
Best score: 0.7683198499237894
Best parameters: {'lr__C': 30, 'lr__penalty': 'l2', 'tfidf__norm': 'l2', 'tfidf__use_idf': True, 'vect__analyzer': 'word', 'vect__min_df': 1, 'vect__ngram_range': (1, 2), 'vect__stop_words': None} 
Best estimator: Pipeline(memory=None,
         steps=[('vect',
                 CountVectorizer(analyzer='word', binary=False,
                                 decode_error='strict',
                                 dtype=<class 'numpy.int64'>, encoding='utf-8',
                                 input='content', lowercase=True, max_df=1.0,
                                 max_features=None, min_df=1,
                                 ngram_range=(1, 2), preprocessor=None,
                                 stop_words=None, strip_accents='ascii',
                                 token_pattern='(?u)\\b\\w\\w+\\b',
                                 tokenizer=None, vocabulary=...)),
                ('tfidf',
                 TfidfTransformer(norm='l2', smooth_idf=True,
                                  sublinear_tf=False, use_idf=True)),
                ('lr',
                 LogisticRegression(C=30, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=100,
                                    multi_class='warn', n_jobs=None,
                                    penalty='l2', random_state=None,
                                    solver='liblinear', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False) 

=== Repr of Classifier ===
GridSearchCV(cv=4, error_score='raise',
             estimator=Pipeline(memory=None,
                                steps=[('vect',
                                        CountVectorizer(analyzer='word',
                                                        binary=False,
                                                        decode_error='strict',
                                                        dtype=<class 'numpy.int64'>,
                                                        encoding='utf-8',
                                                        input='content',
                                                        lowercase=True,
                                                        max_df=1.0,
                                                        max_features=None,
                                                        min_df=1,
                                                        ngram_range=(1, 1),
                                                        preprocessor=None,
                                                        stop_words=None,
                                                        strip_accents='ascii',
                                                        token_patter...
             param_grid={'lr__C': [0.01, 0.03, 0.2, 0.4, 0.6, 0.8, 1, 3, 10,
                                   30],
                         'lr__penalty': ['l1', 'l2'],
                         'tfidf__norm': ['l1', 'l2'],
                         'tfidf__use_idf': [True, False],
                         'vect__analyzer': ['word',
                                            <function processing_analyzer at 0x7f5e5535a840>],
                         'vect__min_df': [1, 2, 3],
                         'vect__ngram_range': [(1, 2), (1, 3)],
                         'vect__stop_words': ['english', None]},
             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,
             scoring='accuracy', verbose=1)

=== Meta ===
Report generated at (UTC): 2019-08-04 10:19:12.628100